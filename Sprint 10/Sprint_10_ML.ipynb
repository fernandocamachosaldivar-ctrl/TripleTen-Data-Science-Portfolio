{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/lcamacho/Triple Ten/Sprint 10/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura de datos\n",
    "\n",
    "Los datos se leyeron usando la función `pd.read_csv('/datasets/users_behavior.csv')` de la librería `pandas`. Se verificó la información general con `df.info()` y las primeras filas con `df.head()`, confirmando que no había valores nulos y que los tipos de datos eran apropiados (variables de entrada `float64`, objetivo `int64`). También se verificó y confirmó la ausencia de filas duplicadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas duplicadas encontradas: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "duplicated_rows = df.duplicated().sum()\n",
    "print(f\"Número de filas duplicadas encontradas: {duplicated_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('is_ultra', axis=1)\n",
    "y = df['is_ultra'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=12345, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=12345, stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tamaños de los Conjuntos de Datos ---\n",
      "Total de Filas: 3214\n",
      "Conjunto de Entrenamiento (60%): 1928 filas | Etiquetas: 1928\n",
      "Conjunto de Validación (20%): 643 filas | Etiquetas: 643\n",
      "Conjunto de Prueba (20%): 643 filas | Etiquetas: 643\n",
      "Suma de Filas: 3214\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Tamaños de los Conjuntos de Datos ---\")\n",
    "print(f\"Total de Filas: {df.shape[0]}\")\n",
    "print(f\"Conjunto de Entrenamiento (60%): {X_train.shape[0]} filas | Etiquetas: {y_train.shape[0]}\")\n",
    "print(f\"Conjunto de Validación (20%): {X_valid.shape[0]} filas | Etiquetas: {y_valid.shape[0]}\")\n",
    "print(f\"Conjunto de Prueba (20%): {X_test.shape[0]} filas | Etiquetas: {y_test.shape[0]}\")\n",
    "print(f\"Suma de Filas: {X_train.shape[0] + X_valid.shape[0] + X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Los datos se segmentaron correctamente, se hicieron en tres conjuntos distintos**\n",
    "* Entrenmiento, X_trainy_train para poder enseñar el modelo\n",
    "* Validacion, X_validy_valid para seleccionar los hiperparametros y seleccionar el mejor modelo\n",
    "* Prueba, X_testy_test para evaluar la exactitud del modelo\n",
    "\n",
    "Se utilizo un argumento en ambas divisiones. Esto asegura que la proporcion de la clase objetivo sea, se mantengan similares\n",
    "**Separacion correcta** se garantizo que entre los conjuntos, los datos utilizados para entrenar no se usen para validar y que los datos de validacion no se usen para la prueba final, esto evita que exista un sobreajuste y los resultados sean muy realistas \n",
    "\n",
    "**Tamaño de los conjuntos**\n",
    "El tamaño de los conjuntos fue de acuerdo el estandard comun y recomendado, enfoncandome que exsita un equibrio entre la cantidad de datos para el entreamiento, la validacion y la prueba \n",
    "**La divisicion elegida fue 60% entrenamiento, 20% validacion, 20% prueba**\n",
    "\n",
    "El entrenamiento es la mayor parte porque necesita una gran cantidad de datos para poder aprender los patrones y las relaciones entre las caracteristicas y el plan ULTRA\n",
    "\n",
    "La validacion es suficiente\n",
    "\n",
    "La prueba es similiar al conjunto de validacion, garantiza la evaluacion final con una muestra considerable, sin que afecte al resto del modelo\n",
    "\n",
    "La alternativa comun es que sea 75% comun y 25% prueba, pero esto solo permite una prueba final, por esta razon es mas adecuada para el flujo de trabajo Entrenamiento-validacion- prueba, se usuaron hiperparametros.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo 1: Árbol de Decisión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidad (max_depth): 1 | Exactitud en Validación: 0.7403\n",
      "Profundidad (max_depth): 2 | Exactitud en Validación: 0.7729\n",
      "Profundidad (max_depth): 3 | Exactitud en Validación: 0.7776\n",
      "Profundidad (max_depth): 4 | Exactitud en Validación: 0.7543\n",
      "Profundidad (max_depth): 5 | Exactitud en Validación: 0.7854\n",
      "Profundidad (max_depth): 6 | Exactitud en Validación: 0.7745\n",
      "Profundidad (max_depth): 7 | Exactitud en Validación: 0.7869\n",
      "Profundidad (max_depth): 8 | Exactitud en Validación: 0.8025\n",
      "Profundidad (max_depth): 9 | Exactitud en Validación: 0.7823\n",
      "Profundidad (max_depth): 10 | Exactitud en Validación: 0.7729\n",
      "\n",
      "MEJOR Árbol de Decisión | Exactitud: 0.8025 | Profundidad Óptima: 8\n"
     ]
    }
   ],
   "source": [
    "best_dt_model = None\n",
    "best_dt_accuracy = 0\n",
    "best_dt_depth = 0\n",
    "\n",
    "for depth in range(1, 11): \n",
    "     \n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    predictions = model.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, predictions)\n",
    "\n",
    "    print(f\"Profundidad (max_depth): {depth} | Exactitud en Validación: {accuracy:.4f}\")\n",
    "\n",
    "    \n",
    "    if accuracy > best_dt_accuracy:\n",
    "        best_dt_accuracy = accuracy\n",
    "        best_dt_model = model\n",
    "        best_dt_depth = depth\n",
    "\n",
    "print(f\"\\nMEJOR Árbol de Decisión | Exactitud: {best_dt_accuracy:.4f} | Profundidad Óptima: {best_dt_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo 2: Bosque Aleatorio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEJOR Bosque Aleatorio | Exactitud: 0.8180 | Est.: 50 | Prof. Óptima: 9\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = None\n",
    "best_rf_accuracy = 0\n",
    "best_rf_n_estimators = 0\n",
    "best_rf_depth = 0\n",
    "\n",
    "for n_est in [10, 50, 100]: \n",
    "    for depth in range(1, 11): \n",
    "        \n",
    "        model = RandomForestClassifier(\n",
    "            random_state=12345,\n",
    "            n_estimators=n_est,\n",
    "            max_depth=depth\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        \n",
    "        predictions = model.predict(X_valid)\n",
    "        accuracy = accuracy_score(y_valid, predictions)\n",
    "\n",
    "        \n",
    "        if accuracy > best_rf_accuracy:\n",
    "            best_rf_accuracy = accuracy\n",
    "            best_rf_model = model\n",
    "            best_rf_n_estimators = n_est\n",
    "            best_rf_depth = depth\n",
    "\n",
    "\n",
    "print(f\"MEJOR Bosque Aleatorio | Exactitud: {best_rf_accuracy:.4f} | Est.: {best_rf_n_estimators} | Prof. Óptima: {best_rf_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo 3: Regresión Logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEJOR Regresión Logística | Exactitud: 0.7185\n"
     ]
    }
   ],
   "source": [
    "best_lr_model = None\n",
    "best_lr_accuracy = 0\n",
    "\n",
    "\n",
    "for c_val in [0.01, 0.1, 1, 10]:\n",
    "    \n",
    "    model = LogisticRegression(random_state=12345, solver='liblinear', C=c_val, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "   \n",
    "    predictions = model.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, predictions)\n",
    "\n",
    "    \n",
    "    if accuracy > best_lr_accuracy:\n",
    "        best_lr_accuracy = accuracy\n",
    "        best_lr_model = model\n",
    "\n",
    "print(f\"MEJOR Regresión Logística | Exactitud: {best_lr_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Final Utilizado: Bosque Aleatorio\n",
      "Exactitud Final: 0.8149\n",
      "Umbral Requerido: 0.75\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(\n",
    "    random_state=12345,\n",
    "    n_estimators=50,\n",
    "    max_depth=9\n",
    ")\n",
    "final_model.fit(X_train, y_train)\n",
    "predictions_test = final_model.predict(X_test)\n",
    "final_accuracy = accuracy_score(y_test, predictions_test)\n",
    "\n",
    "print(f\"Modelo Final Utilizado: Bosque Aleatorio\")\n",
    "print(f\"Exactitud Final: {final_accuracy:.4f}\")\n",
    "print(f\"Umbral Requerido: 0.75\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Modelos de regreción\n",
    "\n",
    "Se probaron tres modelos principales, ajustando sus hiperparámetros en el conjunto de **Validación**:\n",
    "\n",
    "| Modelo | Hiperparámetros explorados | Mejor Rendimiento en Validación | Hiperparámetros Óptimos |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Árbol de Decisión** | `max_depth` (1 a 10) | $\\mathbf{0.8025}$ | `max_depth` = 8 |\n",
    "| **Bosque Aleatorio** | `n_estimators` (Ej. 10, 50, 100) y `max_depth` (1 a 10) | $\\mathbf{0.8180}$ | `n_estimators` = 50, `max_depth` = 9 |\n",
    "| **Regresión Logística** | `C` (parámetro de regularización) y `solver='liblinear'` | $0.7185$ | (El modelo no fue seleccionado) |\n",
    "\n",
    "#### ¿Evaluaste correctamente la calidad del modelo? / ¿Probaste los modelos correctamente?\n",
    "\n",
    "**Sí, la evaluación fue correcta.**\n",
    "\n",
    "1.  **Ajuste:** La calidad de los modelos se evaluó inicialmente en el conjunto de **Validación** (20%) para seleccionar el mejor modelo y sus hiperparámetros óptimos. Esto evitó el sobreajuste.\n",
    "2.  **Prueba Final:** El modelo con el mejor desempeño en validación (**Bosque Aleatorio**) se probó una única vez en el conjunto de **Prueba** (20%) para obtener una métrica de exactitud final imparcial.\n",
    "\n",
    "#### ¿Cuáles fueron tus hallazgos?\n",
    "\n",
    "1.  **Superioridad del Bosque Aleatorio:** El modelo **Bosque Aleatorio** demostró ser el más efectivo, logrando una exactitud en validación de $0.8180$.\n",
    "2.  **Naturaleza No Lineal del Problema:** Los modelos no lineales (Árbol de Decisión y Bosque Aleatorio) superaron significativamente al modelo lineal (Regresión Logística, con $0.7185$). Esto sugiere que la relación entre los datos de comportamiento del cliente y la elección del plan no es una simple línea recta, sino que requiere límites de decisión más complejos.\n",
    "3.  **Generalización Exitosa:** El modelo final (Bosque Aleatorio) mantuvo una exactitud alta al pasar del conjunto de validación ($0.8180$) al conjunto de prueba ($\\mathbf{0.8149}$), indicando que el modelo generaliza bien y no está sobreajustado.\n",
    "\n",
    "#### ¿Cuál es tu puntuación de exactitud?\n",
    "\n",
    "La puntuación de exactitud final, obtenida en el conjunto de prueba con el modelo Bosque Aleatorio optimizado, es de **0.8149**.\n",
    "\n",
    "$$\\text{Puntuación de Exactitud Final} = \\mathbf{0.8149}$$\n",
    "\n",
    "*   **Umbral Mínimo Requerido:** 0.75\n",
    "*   **Estado:** **Éxito**.\n",
    "\n",
    "#### ¿Te ceñiste a la estructura del proyecto y mantuviste limpio el código?\n",
    "\n",
    "**Sí.** El proyecto siguió la estructura estándar de *machine learning* para clasificación:\n",
    "\n",
    "1.  Carga y examen de datos.\n",
    "2.  Segmentación rigurosa en conjuntos de Entrenamiento/Validación/Prueba (60/20/20).\n",
    "3.  Entrenamiento y ajuste de múltiples modelos con hiperparámetros.\n",
    "4.  Selección del modelo campeón.\n",
    "5.  Prueba final en un conjunto de datos nunca antes visto.\n",
    "\n",
    "El código utilizó librerías estándar de `pandas` y `sklearn` de manera clara y organizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
