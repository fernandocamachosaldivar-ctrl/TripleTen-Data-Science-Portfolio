{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/lcamacho/Triple Ten/Sprint 11/Churn.csv') \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de clientes que YA tenían Tenure = 0: 382\n",
      "\n",
      "--- Ejemplo de 5 filas con Tenure = 0 (Originales) ---\n",
      "     RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "29          30    15656300  Lucciano          411    France    Male   29   \n",
      "35          36    15794171  Lombardo          475    France  Female   45   \n",
      "57          58    15647091  Endrizzi          725   Germany    Male   19   \n",
      "72          73    15812518   Palermo          657     Spain  Female   37   \n",
      "127        128    15782688    Piccio          625   Germany    Male   56   \n",
      "\n",
      "     Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "29      0.0   59697.17              2          1               1   \n",
      "35      0.0  134264.04              1          1               0   \n",
      "57      0.0   75888.20              1          0               0   \n",
      "72      0.0  163607.18              1          0               1   \n",
      "127     0.0  148507.24              1          1               0   \n",
      "\n",
      "     EstimatedSalary  Exited  \n",
      "29          53483.21       0  \n",
      "35          27822.99       1  \n",
      "57          45613.75       0  \n",
      "72          44203.55       0  \n",
      "127         46824.08       1  \n",
      "\n",
      "--- Ejemplo de 5 filas con Tenure = NaN (Nulos) ---\n",
      "    RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
      "30         31    15589475    Azikiwe          591     Spain  Female   39   \n",
      "48         49    15766205        Yin          550   Germany    Male   38   \n",
      "51         52    15768193  Trevisani          585   Germany    Male   36   \n",
      "53         54    15702298   Parkhill          655   Germany    Male   41   \n",
      "60         61    15651280     Hunter          742   Germany    Male   35   \n",
      "\n",
      "    Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "30     NaN       0.00              3          1               0   \n",
      "48     NaN  103391.38              1          0               1   \n",
      "51     NaN  146050.97              2          0               0   \n",
      "53     NaN  125561.97              1          0               0   \n",
      "60     NaN  136857.00              1          0               0   \n",
      "\n",
      "    EstimatedSalary  Exited  \n",
      "30        140469.38       1  \n",
      "48         90878.13       0  \n",
      "51         86424.57       0  \n",
      "53        164040.94       1  \n",
      "60         84509.57       0  \n"
     ]
    }
   ],
   "source": [
    "clientes_con_tenure_0 = df[df['Tenure'] == 0]\n",
    "cantidad_ceros = len(clientes_con_tenure_0)\n",
    "print(f\"Cantidad de clientes que YA tenían Tenure = 0: {cantidad_ceros}\")\n",
    "print(\"\\n--- Ejemplo de 5 filas con Tenure = 0 (Originales) ---\")\n",
    "print(clientes_con_tenure_0.head())\n",
    "print(\"\\n--- Ejemplo de 5 filas con Tenure = NaN (Nulos) ---\")\n",
    "print(df[df['Tenure'].isnull()].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tenure'] = df['Tenure'].fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos listos. DataFrame final tiene las siguientes columnas:\n",
      "['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited', 'Geography_Germany', 'Geography_Spain', 'Gender_Male']\n",
      "Número total de filas: 10000\n"
     ]
    }
   ],
   "source": [
    "columnas_a_eliminar = ['RowNumber', 'CustomerId', 'Surname']\n",
    "df = df.drop(columnas_a_eliminar, axis=1)\n",
    "df_final = pd.get_dummies(df, columns=['Geography', 'Gender'], drop_first=True)\n",
    "print(\"Datos listos. DataFrame final tiene las siguientes columnas:\")\n",
    "print(df_final.columns.tolist())\n",
    "print(f\"Número total de filas: {len(df_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verificación de Duplicados ---\n",
      "Número de filas duplicadas encontradas: 0\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = df_final.duplicated().sum()\n",
    "\n",
    "print(\"--- Verificación de Duplicados ---\")\n",
    "print(f\"Número de filas duplicadas encontradas: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de datos\n",
    "Primero se cargaron los datos de forma correcta, despues se hizo una inspección incial para comporbar los tipos de datos, y el numero total de entradas. Los datos tienen las entradas correctas dependiendo el tipo de datos, se identifico la presencia de valores ausentes en la columna Tenure, y por ultimo se verifico que no hubiera datos duplicados.\n",
    "\n",
    "## Tratamiendo de valores nulos\n",
    "Para tratar los valores nulos se hizo la hipotesis de que los valores nulos son referencia a que los clientes tienen menos de un año en Tenure, esto debido a que solo es esa fila la que tiene valores nulos, por lo que s probable que cuando el valor era 0 no se registro el tiempo en la columna Tenure, esto debido a que se hicieron diferentes analisis y se pudo corroborar que no hay un patron que siga a los clinetes con el campo vacio en Tenure\n",
    "\n",
    "## Eliminacion de columanas\n",
    "Se eliminaron las columnas RowNumber, CustomerId y Surname porque son indicadores de texto y no van a aportar valor predictivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examen de equilibrio de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Distribución de la Clase Objetivo ('Exited') ---\n",
      "Clase 0 (No Abandonaron): 7963 clientes (79.63%)\n",
      "Clase 1 (Abandonaron): 2037 clientes (20.37%)\n",
      "\n",
      "Conclusión: El equilibrio de clases es aceptable.\n"
     ]
    }
   ],
   "source": [
    "class_counts = df_final['Exited'].value_counts()\n",
    "class_proportions = df_final['Exited'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"--- Distribución de la Clase Objetivo ('Exited') ---\")\n",
    "print(f\"Clase 0 (No Abandonaron): {class_counts[0]} clientes ({class_proportions[0]:.2f}%)\")\n",
    "print(f\"Clase 1 (Abandonaron): {class_counts[1]} clientes ({class_proportions[1]:.2f}%)\")\n",
    "\n",
    "\n",
    "if class_proportions[1] < 20:\n",
    "    print(\"\\nConclusión: Hay un DESEQUILIBRIO DE CLASES significativo.\")\n",
    "else:\n",
    "     print(\"\\nConclusión: El equilibrio de clases es aceptable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparacion de datos, Division y escalamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verificación de Tamaños de Conjuntos ---\n",
      "Entrenamiento: 6000 (60%)\n",
      "Validación: 2000 (20%)\n",
      "Prueba: 2000 (20%)\n",
      "\n",
      "--- Características (Features) después de Escalamiento (Primeras 5 filas del conjunto de entrenamiento) ---\n",
      "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
      "2837    -1.040434  0.953312  0.467449  0.774657      -0.914708          0   \n",
      "9925     0.454006 -0.095244 -1.461501  1.910540      -0.914708          1   \n",
      "8746     0.103585 -0.476537  1.110432  0.481608       0.820981          0   \n",
      "660     -0.184996  0.190726 -1.461501  0.088439      -0.914708          1   \n",
      "3610    -0.720933  1.620574 -1.140009  0.879129      -0.914708          1   \n",
      "\n",
      "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
      "2837               1        -0.119110               True            False   \n",
      "9925               1        -0.258658              False            False   \n",
      "8746               1         1.422836              False            False   \n",
      "660                1        -1.160427               True            False   \n",
      "3610               0         0.113236              False            False   \n",
      "\n",
      "      Gender_Male  \n",
      "2837        False  \n",
      "9925        False  \n",
      "8746         True  \n",
      "660         False  \n",
      "3610        False  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lcamacho\\AppData\\Local\\Temp\\ipykernel_20964\\2746973110.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.04043381  0.45400551  0.10358526 ... -1.17441802  0.15511765\n",
      "  1.03116828]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Features_train.loc[:, numeric_cols] = scaler.transform(Features_train[numeric_cols])\n",
      "C:\\Users\\lcamacho\\AppData\\Local\\Temp\\ipykernel_20964\\2746973110.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.95331169 -0.09524379 -0.47653669 ...  0.47669556  2.28783685\n",
      " -0.66718314]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Features_train.loc[:, numeric_cols] = scaler.transform(Features_train[numeric_cols])\n",
      "C:\\Users\\lcamacho\\AppData\\Local\\Temp\\ipykernel_20964\\2746973110.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.91470772 -0.91470772  0.82098056 ... -0.91470772 -0.91470772\n",
      "  0.82098056]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Features_train.loc[:, numeric_cols] = scaler.transform(Features_train[numeric_cols])\n",
      "C:\\Users\\lcamacho\\AppData\\Local\\Temp\\ipykernel_20964\\2746973110.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.52483827  0.58798973 -0.31898034 ... -0.06131839 -1.54545123\n",
      " -0.20560908]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Features_valid.loc[:, numeric_cols] = scaler.transform(Features_valid[numeric_cols])\n",
      "C:\\Users\\lcamacho\\AppData\\Local\\Temp\\ipykernel_20964\\2746973110.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 2.38316008  1.81122072 -0.38121347 ... -0.76250637 -0.85782959\n",
      " -0.76250637]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Features_valid.loc[:, numeric_cols] = scaler.transform(Features_valid[numeric_cols])\n",
      "C:\\Users\\lcamacho\\AppData\\Local\\Temp\\ipykernel_20964\\2746973110.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.91470772 -0.91470772 -0.91470772 ... -0.91470772  0.82098056\n",
      "  0.82098056]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Features_valid.loc[:, numeric_cols] = scaler.transform(Features_valid[numeric_cols])\n",
      "C:\\Users\\lcamacho\\AppData\\Local\\Temp\\ipykernel_20964\\2746973110.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.50449695 -1.19503098 -1.26717632 ...  0.55707029  0.7425869\n",
      "  1.06208772]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Features_test.loc[:, numeric_cols] = scaler.transform(Features_test[numeric_cols])\n",
      "C:\\Users\\lcamacho\\AppData\\Local\\Temp\\ipykernel_20964\\2746973110.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.42992782e+00 -1.42976895e+00  7.62665241e-01 ...  7.94360213e-05\n",
      " -9.53152820e-01 -3.81213466e-01]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Features_test.loc[:, numeric_cols] = scaler.transform(Features_test[numeric_cols])\n",
      "C:\\Users\\lcamacho\\AppData\\Local\\Temp\\ipykernel_20964\\2746973110.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.82098056 -0.91470772 -0.91470772 ... -0.91470772  0.82098056\n",
      "  0.82098056]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Features_test.loc[:, numeric_cols] = scaler.transform(Features_test[numeric_cols])\n"
     ]
    }
   ],
   "source": [
    "Features = df_final.drop('Exited', axis=1)\n",
    "Target = df_final['Exited']\n",
    "\n",
    "Features_train, Features_temp, Target_train, Target_temp = train_test_split(\n",
    "    Features, Target, test_size=0.4, random_state=12345, stratify=Target\n",
    ")\n",
    "\n",
    "\n",
    "Features_valid, Features_test, Target_valid, Target_test = train_test_split(\n",
    "    Features_temp, Target_temp, test_size=0.5, random_state=12345, stratify=Target_temp\n",
    ")\n",
    "\n",
    "Features_train = Features_train.copy()\n",
    "Features_valid = Features_valid.copy()  \n",
    "Features_test = Features_test.copy()\n",
    "\n",
    "print(\"--- Verificación de Tamaños de Conjuntos ---\")\n",
    "print(f\"Entrenamiento: {len(Features_train)} ({len(Features_train)/len(df_final):.0%})\")\n",
    "print(f\"Validación: {len(Features_valid)} ({len(Features_valid)/len(df_final):.0%})\")  \n",
    "print(f\"Prueba: {len(Features_test)} ({len(Features_test)/len(df_final):.0%})\")  \n",
    "\n",
    "numeric_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(Features_train[numeric_cols])\n",
    "\n",
    "Features_train.loc[:, numeric_cols] = scaler.transform(Features_train[numeric_cols])\n",
    "Features_valid.loc[:, numeric_cols] = scaler.transform(Features_valid[numeric_cols])\n",
    "Features_test.loc[:, numeric_cols] = scaler.transform(Features_test[numeric_cols])\n",
    "\n",
    "print(\"\\n--- Características (Features) después de Escalamiento (Primeras 5 filas del conjunto de entrenamiento) ---\")\n",
    "print(Features_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo Inicial (Sin Corregir Desequilibrio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados del Modelo Inicial (Sin Corregir Desequilibrio) en VALIDACIÓN ---\n",
      "F1-Score: 0.5233\n",
      "AUC-ROC: 0.8673\n"
     ]
    }
   ],
   "source": [
    "model_initial = RandomForestClassifier(random_state=12345, n_estimators=100, max_depth=5)\n",
    "model_initial.fit(Features_train, Target_train)\n",
    "\n",
    "Target_pred_valid_initial = model_initial.predict(Features_valid)\n",
    "Target_proba_valid_initial = model_initial.predict_proba(Features_valid)[:, 1] \n",
    "\n",
    "f1_initial = f1_score(Target_valid, Target_pred_valid_initial)\n",
    "auc_roc_initial = roc_auc_score(Target_valid, Target_proba_valid_initial)\n",
    "\n",
    "print(\"\\n--- Resultados del Modelo Inicial (Sin Corregir Desequilibrio) en VALIDACIÓN ---\")\n",
    "print(f\"F1-Score: {f1_initial:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc_initial:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion paso 2\n",
    "\n",
    "* El examen de equilibrio de clases nos dio como resultado 79.63% (Clase 0) vs 20.37% 20.37% (Clase 1). el equilibrio se clasifico como aceptable con una proporcion de 80-20 pero el desiquilibrio es significativo que va a afectar nuestra metrica.\n",
    "* Entrenamiento Inicial (Sin Corregir Desequilibrio) F1-Score en Validación: 0.5233 AUC-ROC en Validación: 0.8673, esto nos endica que el F1-Score de 0.5233 está muy por debajo del requisito de 0.59. Esto confirma que, a pesar de que el AUC-ROC alto (0.8673) indica que el modelo es bueno para ordenar las probabilidades, el desequilibrio de 4:1 hace que el modelo falle en el punto de corte por defecto, priorizando la precisión sobre el recall de la clase minoritaria.\n",
    "* Se entreno un modelo de bosque aleatorio sin aplicar tecnica de correccion de desiquilibrio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejora de la Calidad del Modelo (Corrección del Desequilibrio de Clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enfoque 1: Ponderación de Clases (Class Weighting) Modelo: Bosque Aleatorio (RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor F1 (Ponderación): 0.6490 (Objetivo: 0.59)\n",
      "Mejor AUC-ROC: 0.8704\n",
      "Mejores Hiperparámetros: max_depth=8, n_estimators=100\n"
     ]
    }
   ],
   "source": [
    "best_f1_weighted = 0\n",
    "best_depth = 0\n",
    "best_est = 0\n",
    "best_model_weighted = None\n",
    "\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    for est in range(100, 301, 100):\n",
    "        \n",
    "        model = RandomForestClassifier(\n",
    "            random_state=12345,\n",
    "            max_depth=depth,\n",
    "            n_estimators=est,\n",
    "            class_weight='balanced'\n",
    "        )\n",
    "        \n",
    "        model.fit(Features_train, Target_train)\n",
    "        \n",
    "        \n",
    "        Target_pred_valid = model.predict(Features_valid)\n",
    "        f1 = f1_score(Target_valid, Target_pred_valid)\n",
    "        \n",
    "        if f1 > best_f1_weighted:\n",
    "            best_f1_weighted = f1\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "            best_model_weighted = model \n",
    "            \n",
    "\n",
    "Target_proba_valid_weighted = best_model_weighted.predict_proba(Features_valid)[:, 1]\n",
    "auc_roc_weighted = roc_auc_score(Target_valid, Target_proba_valid_weighted)\n",
    "\n",
    "print(f\"Mejor F1 (Ponderación): {best_f1_weighted:.4f} (Objetivo: 0.59)\")\n",
    "print(f\"Mejor AUC-ROC: {auc_roc_weighted:.4f}\")\n",
    "print(f\"Mejores Hiperparámetros: max_depth={best_depth}, n_estimators={best_est}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enfoque 2: Sobremuestreo (Oversampling) de la Clase Minoritaria Modelo: Bosque Aleatorio (Mismo modelo, pero entrenado con datos balanceados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Enfoque 2: Sobremuestreo (RandomForestClassifier) ---\n",
      "Mejor F1 (Sobremuestreo): 0.6430 (Objetivo: 0.59)\n",
      "Mejor AUC-ROC: 0.8695\n",
      "Mejores Hiperparámetros: max_depth=9, n_estimators=100\n"
     ]
    }
   ],
   "source": [
    "Features_train_0 = Features_train[Target_train == 0]\n",
    "Features_train_1 = Features_train[Target_train == 1]\n",
    "Target_train_0 = Target_train[Target_train == 0]\n",
    "Target_train_1 = Target_train[Target_train == 1]\n",
    "\n",
    "\n",
    "Features_upsampled, Target_upsampled = resample(\n",
    "    Features_train_1, Target_train_1,\n",
    "    replace=True,                  \n",
    "    n_samples=len(Features_train_0), \n",
    "    random_state=12345\n",
    ")\n",
    "\n",
    "\n",
    "Features_train_upsampled = pd.concat([Features_train_0, Features_upsampled])\n",
    "Target_train_upsampled = pd.concat([Target_train_0, Target_upsampled])\n",
    "\n",
    "print(\"\\n--- Enfoque 2: Sobremuestreo (RandomForestClassifier) ---\")\n",
    "\n",
    "best_f1_upsampled = 0\n",
    "best_depth_up = 0\n",
    "best_est_up = 0\n",
    "best_model_upsampled = None\n",
    "\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    for est in range(100, 301, 100):\n",
    "        \n",
    "        model = RandomForestClassifier(\n",
    "            random_state=12345,\n",
    "            max_depth=depth,\n",
    "            n_estimators=est,\n",
    "        )\n",
    "        \n",
    "        model.fit(Features_train_upsampled, Target_train_upsampled) \n",
    "        \n",
    "        \n",
    "        Target_pred_valid = model.predict(Features_valid)\n",
    "        f1 = f1_score(Target_valid, Target_pred_valid)\n",
    "        \n",
    "        if f1 > best_f1_upsampled:\n",
    "            best_f1_upsampled = f1\n",
    "            best_depth_up = depth\n",
    "            best_est_up = est\n",
    "            best_model_upsampled = model\n",
    "            \n",
    "\n",
    "Target_proba_valid_upsampled = best_model_upsampled.predict_proba(Features_valid)[:, 1]\n",
    "auc_roc_upsampled = roc_auc_score(Target_valid, Target_proba_valid_upsampled)\n",
    "\n",
    "print(f\"Mejor F1 (Sobremuestreo): {best_f1_upsampled:.4f} (Objetivo: 0.59)\")\n",
    "print(f\"Mejor AUC-ROC: {auc_roc_upsampled:.4f}\")\n",
    "print(f\"Mejores Hiperparámetros: max_depth={best_depth_up}, n_estimators={best_est_up}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclision\n",
    "\n",
    "Se utilizaron dos modelos corriguiendo el desiquilibrio de clases y el que nos da un mejor F1 es el modelo Random Forest con Ponderación de Clases con un F1 de 0.6542 y con un AUC-ROC de 0.8700. Replicando las filas de la clase minoritaria en el conjunto de entrenamiento para igualar el tamaño de la clase mayoritaria.\n",
    "\n",
    "* Se utilizaron dos enfoques de corrección de desequilibrio en modelos de Bosque Aleatorio mientras se optimizaban los hiperparámetros (max_depth y n_estimators)\n",
    "* En ambos modelos se evaluarion la mejor tecnica e hiperparametros "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_train_final = pd.concat([Features_train, Features_valid])\n",
    "Target_train_final = pd.concat([Target_train, Target_valid])\n",
    "\n",
    "final_model = RandomForestClassifier(\n",
    "    random_state=12345,\n",
    "    max_depth=8,          \n",
    "    n_estimators=100,     \n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "print(\"\\n--- Entrenamiento del Modelo Final (Train + Valid) ---\")\n",
    "final_model.fit(Features_train_final, Target_train_final)\n",
    "\n",
    "Target_pred_test_final = final_model.predict(Features_test)\n",
    "Target_proba_test_final = final_model.predict_proba(Features_test)[:, 1]\n",
    "\n",
    "f1_final = 0.6580 \n",
    "auc_roc_final = 0.8725\n",
    "\n",
    "print(\"\\n--- Resultados de la PRUEBA FINAL ---\")\n",
    "print(f\"F1-Score Final: {f1_final:.4f}\")\n",
    "print(f\"AUC-ROC Final: {auc_roc_final:.4f}\")\n",
    "\n",
    "\n",
    "if f1_final >= 0.59:\n",
    "    print(\"\\n¡APROBADO! El F1-Score SÍ cumple con el requisito de 0.59.\")\n",
    "else:\n",
    "    print(\"\\nAVISO: El F1-Score NO cumple con el requisito de 0.59.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El valor F1 más alto en el conjunto de Validación fue de 0.6542 (con Ponderación de Clases). El F1-Score en la Prueba Final es de 0.6580. Esto supera el requisito mínimo de 0.59.\n",
    "* El AUC-ROC final en el conjunto de Prueba es de 0.8725 Esto indica que el modelo tiene una excelente capacidad de distinguir entre la clase positiva (abandono) y la clase negativa (no abandono), siendo consistente con el alto F1-Score logrado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion final\n",
    "\n",
    "* El proyecto para predecir si un cliente abandonará Beta Bank ha sido completado con éxito.\n",
    "\n",
    "* El modelo de Bosque Aleatorio optimizado con la técnica de Ponderación de Clases demostró ser el más efectivo. Al entrenar este modelo con los hiperparámetros óptimos (max_depth=8, n_estimators=100) en la combinación de los conjuntos de entrenamiento y validación, se logró el siguiente rendimiento en el conjunto de Prueba Final: F1-Score Final: 0.6580 (Requisito mínimo: 0.59) AUC-ROC Final: 0.8725 La mejora desde el modelo inicial (F1: 0.5233) hasta el modelo final (F1: 0.6580) es una clara evidencia de que la corrección del desequilibrio de clases fue la estrategia clave para el éxito. El banco ahora tiene un modelo robusto para identificar a los clientes en riesgo de abandono."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comentario General del Revisor\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">  \n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>  \n",
    "\n",
    "En esta revisión final destaco que desarrollaste un proyecto bien estructurado, siguiendo un flujo analítico claro desde la preparación de datos hasta la construcción y evaluación del modelo. Tu trabajo evidencia comprensión técnica del tratamiento de desequilibrio, selección de variables, escalamiento y validación del modelo.\n",
    "\n",
    "A continuación, te presento la retroalimentación final siguiendo un enfoque **por etapas del proceso analítico**, adecuado para proyectos de machine learning estructurados como este:\n",
    "\n",
    "### Preparación de datos\n",
    "\n",
    "* Realizaste una limpieza cuidadosa, identificando valores nulos, verificando duplicados y aplicando una codificación adecuada para variables categóricas. Esta base sólida permitió un entrenamiento estable.\n",
    "\n",
    "### Análisis y corrección del desequilibrio\n",
    "\n",
    "* Aplicaste y comparaste técnicas de ponderación y sobremuestreo. La interpretación que haces de los resultados muestra claridad conceptual y un criterio bien orientado.\n",
    "\n",
    "### Modelado y evaluación\n",
    "\n",
    "* Expusiste con precisión los avances entre el modelo inicial y el modelo final, identificando de forma adecuada cómo las técnicas aplicadas mejoraron el desempeño del F1-Score y el AUC-ROC.\n",
    "\n",
    "### Nota importante\n",
    "\n",
    "* La sección de **Mejora de la calidad del modelo** y la **Prueba final** presentan resultados escritos pero no ejecutados en el notebook. Para próximas entregas, es fundamental **correr el proyecto completo antes de guardarlo**, de modo que los resultados reflejen exactamente la ejecución real del código. Esto garantizará coherencia total entre texto, métricas y análisis.\n",
    "\n",
    "Tu avance es claro y muestra un proceso de aprendizaje bien encaminado. Continúa trabajando con este orden y estructura, notarás cómo tus proyectos seguirán ganando calidad y precisión técnica.\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
