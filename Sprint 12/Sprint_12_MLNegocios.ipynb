{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Review General iteración 1) </b> <a class=\"tocSkip\"></a>\n",
    "    \n",
    "Fernando, has hecho un excelente trabajo con el desarrollo del proyecto, cada vez más cercas de convertirte en un cientifico de datos. Realizaste la carga de bases, su análisis inicial,el desarrollo de los modelos, el calculo del RMSE además lo replicate para todas la regiones y concluiste con el análisis de ganancias. Solamente te dejo algunos comentarios para complementar el análisis.\n",
    "\n",
    "Sigue con el excelente trabajo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_csv('/Users/lcamacho/Triple Ten/Sprint 12/geo_data_0.csv')\n",
    "df_1 = pd.read_csv('/Users/lcamacho/Triple Ten/Sprint 12/geo_data_1.csv')\n",
    "df_2 = pd.read_csv('/Users/lcamacho/Triple Ten/Sprint 12/geo_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "      id        f0        f1        f2     product\n",
      "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
      "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
      "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
      "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
      "4  Xdl7t  1.988431  0.155413  4.751769  154.036647\n"
     ]
    }
   ],
   "source": [
    "df_0.info()\n",
    "print (df_0.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "      id         f0         f1        f2     product\n",
      "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
      "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
      "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
      "4  AHL4O  12.702195  -8.147433  5.004363  134.766305\n"
     ]
    }
   ],
   "source": [
    "df_1.info()\n",
    "print (df_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "      id        f0        f1        f2     product\n",
      "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
      "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
      "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
      "4  WPMUX -0.515993  1.716266  5.899011  149.600746\n"
     ]
    }
   ],
   "source": [
    "df_2.info()\n",
    "print (df_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de duplicados: 0\n",
      "Número de duplicados: 0\n",
      "Número de duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Número de duplicados: {df_0.duplicated().sum()}\")\n",
    "print(f\"Número de duplicados: {df_1.duplicated().sum()}\")\n",
    "print(f\"Número de duplicados: {df_2.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/geo_data_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, path \u001b[38;5;129;01min\u001b[39;00m file_paths\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 9\u001b[0m     dataframes[name] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path)\n\u001b[0;32m     11\u001b[0m df_0 \u001b[38;5;241m=\u001b[39m dataframes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion_0\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m df_1 \u001b[38;5;241m=\u001b[39m dataframes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/geo_data_0.csv'"
     ]
    }
   ],
   "source": [
    "file_paths = {\n",
    "    'region_0': '/datasets/geo_data_0.csv',\n",
    "    'region_1': '/datasets/geo_data_1.csv',\n",
    "    'region_2': '/datasets/geo_data_2.csv'\n",
    "}\n",
    "\n",
    "dataframes = {}\n",
    "for name, path in file_paths.items():\n",
    "    dataframes[name] = pd.read_csv(path)\n",
    "\n",
    "df_0 = dataframes['region_0']\n",
    "df_1 = dataframes['region_1']\n",
    "df_2 = dataframes['region_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Muy buen trabajo cargando tanto las librerías necesarias para el proyecto como el dataset con el separador adecuado. Además, lo complementa con un análisis de valores nulos y complementar con el análisis de duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparacion de datos\n",
    "* Todos los dataframes fueron cargados correctamente\n",
    "* No se encontraron valores ausentes\n",
    "* Los tipos de datos son los correctos de acuerdo a su contenido\n",
    "* No se encontraron datos duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrena de modelo y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def train_and_evaluate_model_v2(df, region_name, random_state=12345):\n",
    "    \n",
    "    features = df.drop(['id', 'product'], axis=1)\n",
    "    target = df['product']\n",
    "\n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "        features, target, test_size=0.25, random_state=random_state\n",
    "    )\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "\n",
    "    target_valid = target_valid.reset_index(drop=True)\n",
    "\n",
    "    mean_product = predictions.mean()\n",
    "    rmse = np.sqrt(mean_squared_error(target_valid, predictions))\n",
    "\n",
    "    print(f\"\\n--- Resultados del Modelo para {region_name} ---\")\n",
    "    print(f\"Volumen Medio de Reservas Predicho: {mean_product:,.2f} miles de barriles\")\n",
    "    print(f\"RMSE (Error Cuadrático Medio de la Raíz): {rmse:,.2f} miles de barriles\")\n",
    "\n",
    "    return predictions, target_valid, mean_product, rmse\n",
    "\n",
    "print(\"--- COMIENZO DEL ENTRENAMIENTO Y EVALUACIÓN (V2) ---\")\n",
    "results['region_0'] = train_and_evaluate_model_v2(df_0, 'Región 0')\n",
    "results['region_1'] = train_and_evaluate_model_v2(df_1, 'Región 1')\n",
    "results['region_2'] = train_and_evaluate_model_v2(df_2, 'Región 2')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis de resultados\n",
    "\n",
    "Los resultados muestran una una diferencia critica en el RMSE medio predicho entre regiones.\n",
    "\n",
    "* Region 0 y 2. Ambas un volumen medio de reservas predicho relativamente alto de 92.59 y 94.97 respectivamente sin embargo el RMSE es muy alto, el error promedio es significativo representando el volumen medio de aproximadamente un 40%, el modelo tiene una regresion lineal de baja presicion en estas regiones, por lo que las predicciones en pozos individualmente son poco fiables. esto aumenta el riesgo de perforar pozos que el modelo sobreestimo, como resultado en perdidas.\n",
    "* Region 1. el volumen predicho es el mas bajo de los tres con 68.73 barriles, pero el RMSE es bajo lo que es muy bueno de 0.89 miles de barriles, el modelo de regresion lineal es casi perfecto, esto suguiere que la regresion lineal entre las filas es muy fuerte con volumen de reservas, como conslusion las fiabilidad de predicciones es muy alta.\n",
    "\n",
    "##### Conclusion\n",
    "\n",
    "La region 2 tiene un mayor nivel de reservas predicho, la region 1 ofrece la mayor confianza en sus predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Fernando, implementaste el modelo de regresión lineal de forma excelente para los 3 conjuntos de datos! En este punto ya puedes obervar cuál es el modelo con el mayor $R^2$ y menor RMSE. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de ganancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUDGET = 100_000_000            \n",
    "INCOME_PER_UNIT = 4500              \n",
    "WELLS_TO_SELECT = 200             \n",
    "STUDY_POINTS = 500\n",
    "\n",
    "COST_PER_WELL = BUDGET / WELLS_TO_SELECT \n",
    "\n",
    "MIN_TOTAL_PRODUCT_VOLUME = BUDGET / INCOME_PER_UNIT\n",
    "\n",
    "\n",
    "MIN_PRODUCT_PER_WELL = MIN_TOTAL_PRODUCT_VOLUME / WELLS_TO_SELECT\n",
    "\n",
    "print(f\"\\n--- Punto de Equilibrio ---\")\n",
    "print(f\"Volumen Mínimo Total de Reservas (200 pozos) para cubrir el presupuesto: {MIN_TOTAL_PRODUCT_VOLUME:,.2f} miles de barriles\")\n",
    "print(f\"Volumen Mínimo Promedio por Pozo para cubrir el costo: {MIN_PRODUCT_PER_WELL:,.2f} miles de barriles\")\n",
    "\n",
    "print(f\"Media de Reservas Real (Target) - Región 0: {df_0['product'].mean():,.2f} miles de barriles\")\n",
    "print(f\"Media de Reservas Real (Target) - Región 1: {df_1['product'].mean():,.2f} miles de barriles\")\n",
    "print(f\"Media de Reservas Real (Target) - Región 2: {df_2['product'].mean():,.2f} miles de barriles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analsis de resultados\n",
    "\n",
    "* Ninguna de las 3 regiones, en promedio, produce el volumen de reservas necesario para que un pozo promedio cubra su parte del costo de desarrollo, esto refuerza el uso de un machine learning para seleccionar los pozos mas prometedores con un conjunto mas grande ya que no se puede confiar en el rendimiento promedio de la region\n",
    "* la estrategia debe de concentrarce en la seleccion de los mejores 200 pozos basandonos en las predicciones de un modelo y no en el volumen promedio de cada region. nos enfocaremos en la ganancia en la metrica de ganancia potencial combinada con el riesgo de perdida "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funsion para calcular ganancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUDGET = 100_000_000      \n",
    "INCOME_PER_UNIT = 4500    \n",
    "WELLS_TO_SELECT = 200\n",
    "\n",
    "def calculate_profit(target, predictions, count=WELLS_TO_SELECT):\n",
    "    \n",
    "    data = pd.DataFrame({'target': target, 'predictions': predictions})\n",
    "\n",
    "    sorted_predictions = data.sort_values(by='predictions', ascending=False)\n",
    "    selected_wells = sorted_predictions.head(count)\n",
    "\n",
    "    sum_actual_product = selected_wells['target'].sum() \n",
    "\n",
    "    total_income = sum_actual_product * INCOME_PER_UNIT\n",
    "\n",
    "    total_cost = BUDGET\n",
    "\n",
    "    profit = total_income - total_cost\n",
    "\n",
    "    return profit, sum_actual_product\n",
    "\n",
    "regions = {\n",
    "    'Región 0': {'predictions': results['region_0'][0], 'target': results['region_0'][1]},\n",
    "    'Región 1': {'predictions': results['region_1'][0], 'target': results['region_1'][1]},\n",
    "    'Región 2': {'predictions': results['region_2'][0], 'target': results['region_2'][1]},\n",
    "}\n",
    "\n",
    "profit_results = {}\n",
    "\n",
    "print(\"\\n--- CÁLCULO DE LA GANANCIA POTENCIAL DE LOS 200 POZOS PRINCIPALES ---\")\n",
    "\n",
    "for region_name, data in regions.items():\n",
    "    profit, sum_product = calculate_profit(data['target'], data['predictions'])\n",
    "    profit_results[region_name] = {'profit': profit, 'total_product': sum_product}\n",
    "\n",
    "    print(f\"\\n{region_name}:\")\n",
    "    print(f\"  Volumen Total de Reservas (Real) en los 200 pozos seleccionados: {sum_product:,.2f} miles de barriles\")\n",
    "    print(f\"  Volumen de Equilibrio Requerido: {MIN_TOTAL_PRODUCT_VOLUME:,.2f} miles de barriles\")\n",
    "    print(f\"  Ganancia Potencial (Ingreso - Costo): ${profit:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis de datos\n",
    "\n",
    "* La region 0 presenta la mayor ganancia potencial con $33,208,260.43. pero todas las regiones superan con creces el volumen de reservas requerido para el punto de equilibrio demostrando el exito de los mejores pozos.\n",
    "* Basandonos unicamente en la ganancia potencial, la region 0 es la mejor opcion. sin embargo no hemos considerado aun el riesgo de perdida ademas de que el RSME de la region 0 y 2 hace que el resultado no sea muy confiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funsion para calcular riesgos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUDGET = 100_000_000\n",
    "WELLS_TO_SELECT = 200\n",
    "STUDY_POINTS = 500  \n",
    "\n",
    "def calculate_profit(target, predictions, count=WELLS_TO_SELECT):\n",
    "    data = pd.DataFrame({'target': target, 'predictions': predictions})\n",
    "    sorted_predictions = data.sort_values(by='predictions', ascending=False)\n",
    "    selected_wells = sorted_predictions.head(count)\n",
    "    sum_actual_product = selected_wells['target'].sum()\n",
    "    total_income = sum_actual_product * INCOME_PER_UNIT\n",
    "    profit = total_income - BUDGET\n",
    "    return profit\n",
    "\n",
    "def analyze_region_with_bootstrap(region_name, target, predictions, iterations=1000, study_size=STUDY_POINTS, random_state=12345):\n",
    "    \n",
    "    data = pd.DataFrame({'target': target, 'predictions': predictions})\n",
    "    state = np.random.RandomState(random_state)\n",
    "    profit_samples = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        sample = data.sample(n=study_size, replace=True, random_state=state)\n",
    "\n",
    "        profit = calculate_profit(sample['target'], sample['predictions'])\n",
    "        profit_samples.append(profit)\n",
    "\n",
    "    profit_samples = pd.Series(profit_samples)\n",
    "\n",
    "    mean_profit = profit_samples.mean()\n",
    "    lower_bound = profit_samples.quantile(0.025)\n",
    "    upper_bound = profit_samples.quantile(0.975)\n",
    "\n",
    "    risk_of_loss = (profit_samples < 0).mean() * 100\n",
    "\n",
    "    print(f\"\\n--- Análisis de Riesgo y Ganancia para {region_name} (Bootstrapping) ---\")\n",
    "    print(f\"Beneficio Promedio: ${mean_profit:,.2f}\")\n",
    "    print(f\"Intervalo de Confianza del 95% (2.5%): ${lower_bound:,.2f}\")\n",
    "    print(f\"Intervalo de Confianza del 95% (97.5%): ${upper_bound:,.2f}\")\n",
    "    print(f\"Riesgo de Pérdidas: {risk_of_loss:.2f}%\")\n",
    "\n",
    "    return mean_profit, risk_of_loss\n",
    "\n",
    "\n",
    "final_results = {}\n",
    "\n",
    "for region_name, data in regions.items():\n",
    "    mean_profit, risk_of_loss = analyze_region_with_bootstrap(\n",
    "        region_name, data['target'], data['predictions']\n",
    "    )\n",
    "    final_results[region_name] = {'mean_profit': mean_profit, 'risk_of_loss': risk_of_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis de resultados\n",
    "\n",
    "* El riesgo de perdidas debe de ser menor al 2.5%, de acuerdo a los resultados las unica region que cumple con el criterio de riesgo con un resultado del 1.5% mientras que las otras dos regiones son mayores al 6%\n",
    "* Por esta razon la region que se debe de elegir es la region 1 ya que su riesgo de perdidas es menor al 2.5%, ademas de que el beneficio promedio es la mas alta con $4,560,451.06 incluso despues de considerar el riesgo\n",
    "* El analisis muestra que aunque la region 0 puede alcanzar una ganancia mas alta pero el modelo impresisio muestra volatibildad lo que podria reflejarse en perdidas, el escoger la region 1 garantiza la probabilidad de obtener un mayor beneficio sustancial generando las ganancias el negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Muy buen trabajo con el calculo de las ganacias para cada una de las regiones. Posteriormente este resultados lo complementas con el análisis de riesgos\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
